# ==========================================================
# Age Group Classification using MobileNetV2 (Fast + Balanced + Accurate + Visualization)
# ==========================================================
import os, numpy as np, matplotlib.pyplot as plt, seaborn as sns, tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.utils.class_weight import compute_class_weight

# ========================== 0. C·∫•u h√¨nh TensorFlow ==========================
tf.config.threading.set_intra_op_parallelism_threads(4)
tf.config.threading.set_inter_op_parallelism_threads(4)
print("‚úÖ TensorFlow ƒëang ch·∫°y t·ªëi ∆∞u ƒëa lu·ªìng CPU.")

# ========================== 1. ƒê∆∞·ªùng d·∫´n d·ªØ li·ªáu ==========================
BASE_DIR = r"C:\Users\ADMIN\UTKFace_split"
TRAIN_DIR, VAL_DIR, TEST_DIR = [os.path.join(BASE_DIR, d) for d in ["train", "val", "test"]]
MODEL_DIR = os.path.join(BASE_DIR, "models")
os.makedirs(MODEL_DIR, exist_ok=True)

target_names = ["Tre em", "Thieu nhi", "Thanh nien", "Trung nien", "Nguoi gia"]
num_classes = len(target_names)

# ========================== 2. Data Augmentation ==========================
IMG_SIZE = (96, 96)
BATCH_SIZE = 16

train_gen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=15,
    width_shift_range=0.15,
    height_shift_range=0.15,
    zoom_range=0.2,
    horizontal_flip=True
).flow_from_directory(
    TRAIN_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical'
)

val_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(
    VAL_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical'
)

test_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(
    TEST_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False
)

# ========================== 3. C√¢n b·∫±ng d·ªØ li·ªáu ==========================
class_weights = compute_class_weight(class_weight='balanced',
                                     classes=np.unique(train_gen.classes),
                                     y=train_gen.classes)
class_weights = dict(enumerate(class_weights))
print("‚öñÔ∏è Tr·ªçng s·ªë l·ªõp:", class_weights)

# ========================== 4. MobileNetV2 base model ==========================
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(96, 96, 3))
for layer in base_model.layers[:-20]:
    layer.trainable = False
for layer in base_model.layers[-20:]:
    layer.trainable = True

# ========================== 5. X√¢y d·ª±ng m√¥ h√¨nh ==========================
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(256, activation='relu'),
    BatchNormalization(),
    Dropout(0.3),
    Dense(num_classes, activation='softmax')
])

model.compile(optimizer=Adam(learning_rate=2e-4),
              loss='categorical_crossentropy',
              metrics=['accuracy'])
model.summary()

# ========================== 6. Callback ==========================
checkpoint_path = os.path.join(MODEL_DIR, "mobilenetv2_balanced_best.h5")
callbacks = [
    EarlyStopping(patience=5, monitor='val_accuracy', restore_best_weights=True),
    ModelCheckpoint(checkpoint_path, save_best_only=True, monitor='val_accuracy', verbose=1),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)
]

# ========================== 7. Hu·∫•n luy·ªán ==========================
history = model.fit(train_gen,
                    validation_data=val_gen,
                    epochs=15,
                    callbacks=callbacks,
                    class_weight=class_weights,
                    verbose=1)

# ========================== 8. ƒê√°nh gi√° ==========================
loss, acc = model.evaluate(test_gen)
print(f"\n‚úÖ ƒê·ªô ch√≠nh x√°c (Test Accuracy): {acc*100:.2f}%")

# ========================== 9. Bi·ªÉu ƒë·ªì hu·∫•n luy·ªán ==========================
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title("ƒê·ªô ch√≠nh x√°c (Accuracy)")
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title("H√†m m·∫•t m√°t (Loss)")
plt.legend()
plt.tight_layout()
plt.show()

# ========================== 10. B√°o c√°o & Ma tr·∫≠n nh·∫ßm l·∫´n ==========================
y_pred = np.argmax(model.predict(test_gen), axis=1)
y_true = test_gen.classes

report = classification_report(y_true, y_pred, target_names=target_names, zero_division=0, output_dict=True)
print("\nüìä B√°o c√°o chi ti·∫øt:")
print(classification_report(y_true, y_pred, target_names=target_names, zero_division=0))

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(7, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=target_names, yticklabels=target_names)
plt.title("Ma tr·∫≠n nh·∫ßm l·∫´n (Confusion Matrix)")
plt.xlabel("D·ª± ƒëo√°n")
plt.ylabel("Th·ª±c t·∫ø")
plt.tight_layout()
cm_path = os.path.join(MODEL_DIR, "mobilenetv2_confusion_matrix.png")
plt.savefig(cm_path)
plt.close()
print(f"üíæ ƒê√£ l∆∞u Confusion Matrix t·∫°i: {cm_path}")

# Precision & Recall
precisions = [report[name]['precision'] for name in target_names]
recalls = [report[name]['recall'] for name in target_names]
x = np.arange(len(target_names))
width = 0.35
plt.figure(figsize=(8, 5))
plt.bar(x - width/2, precisions, width, label='Precision', color='skyblue')
plt.bar(x + width/2, recalls, width, label='Recall', color='salmon')
plt.xticks(x, target_names, rotation=15)
plt.ylim(0, 1)
plt.ylabel("T·ªâ l·ªá")
plt.title("Precision & Recall theo t·ª´ng nh√≥m tu·ªïi")
plt.legend()
plt.tight_layout()
chart_path = os.path.join(MODEL_DIR, "mobilenetv2_class_report.png")
plt.savefig(chart_path)
plt.close()
print(f"üìä L∆∞u bi·ªÉu ƒë·ªì Precision/Recall t·∫°i: {chart_path}")

# ========================== 11. L∆∞u m√¥ h√¨nh ==========================
save_path = os.path.join(MODEL_DIR, "mobilenetv2_final.h5")
model.save(save_path)
print(f"üíæ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {save_path}")
